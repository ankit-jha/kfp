{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DistilBertForSequenceClassification,BertForSequenceClassification, DistilBertTokenizerFast, Trainer, TrainingArguments\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import pipeline\n",
    "import transformers\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import load_dataset\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell purely for checking how much memory we have available\n",
    "\n",
    "t = torch.cuda.get_device_properties(0).total_memory\n",
    "r = torch.cuda.memory_reserved(0)\n",
    "a = torch.cuda.memory_allocated(0)\n",
    "f = r-a  # free inside reserved\n",
    "\n",
    "print(f\"total mem: {t}\\nreserved: {r}\\nallocated: {a}\\nfree in reserve: {f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm that torch is working and it found a device\n",
    "\n",
    "torch.cuda.current_device()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "\n",
    "negative_df = pd.read_csv(\"data/reviews.csv\")[['text', 'negative']]\n",
    "\n",
    "#negative_df = negative_df.rename(columns={\"Neg\":\"labels\"})\n",
    "negative_df = negative_df.rename(columns={\"negative\":\"labels\"})\n",
    "# Quick hack to convert to int\n",
    "negative_df['labels'] = negative_df.labels.astype(int)\n",
    "\n",
    "# filter by length\n",
    "negative_df = negative_df[negative_df.text.map(len) >= 12]\n",
    "\n",
    "# Balance the dataset\n",
    "#Not balancing for now, trying to improve class balance issues.\n",
    "#Back to balancing\n",
    "#negative_df = negative_df[negative_df.labels == 1].append(negative_df[negative_df.labels == 0].sample(negative_df.labels.sum()*9))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do train test split and rebalance\n",
    "\n",
    "from datasets import load_dataset\n",
    "from datasets import Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "sentiment_dataset_train, sentiment_dataset_test = train_test_split(negative_df[['text','labels']], test_size=.0125)\n",
    "\n",
    "# write to CSV for reference\n",
    "sentiment_dataset_train.to_pickle(\"data/transformers_test_data/train.pkl\")\n",
    "sentiment_dataset_test.to_pickle(\"data/transformers_test_data/test.pkl\")\n",
    "\n",
    "# sub sample sentiment TRAINING set, level test set at the same ratio\n",
    "sentiment_dataset_train = sentiment_dataset_train[sentiment_dataset_train.labels == 1].append(sentiment_dataset_train[sentiment_dataset_train.labels == 0].sample(sentiment_dataset_train.labels.sum()*9))\n",
    "\n",
    "sentiment_dataset_train = Dataset.from_pandas(sentiment_dataset_train[['labels','text']])\n",
    "sentiment_dataset_test = Dataset.from_pandas(sentiment_dataset_test[['labels', 'text']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased')\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize with appropriate tokenizer etc.\n",
    "\n",
    "def tokenize(batch):\n",
    "    return tokenizer(batch['text'],\n",
    "                     padding='max_length',\n",
    "                     truncation=True,\n",
    "                     max_length=128,\n",
    "                    )\n",
    "\n",
    "sentiment_dataset_train = sentiment_dataset_train.map(tokenize,\n",
    "                                                      batched=True,\n",
    "                                                      batch_size=32)\n",
    "                                                      #batch_size=len(sentiment_dataset_train))\n",
    "sentiment_dataset_test = sentiment_dataset_test.map(tokenize,\n",
    "                                                    batched=True,\n",
    "                                                    batch_size=32)\n",
    "                                                    #batch_size=len(sentiment_dataset_train))\n",
    "\n",
    "sentiment_dataset_train.set_format('torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "sentiment_dataset_test.set_format('torch', columns=['input_ids', 'attention_mask', 'labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='binary')\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit = 5,\n",
    "    evaluation_strategy='steps',\n",
    "    eval_steps=500,\n",
    "    logging_dir='./logs',\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    compute_metrics=compute_metrics,\n",
    "    train_dataset=sentiment_dataset_train,\n",
    "    eval_dataset=sentiment_dataset_test\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.cuda.get_device_properties(0).total_memory\n",
    "r = torch.cuda.memory_reserved(0)\n",
    "a = torch.cuda.memory_allocated(0)\n",
    "f = r-a  # free inside reserved\n",
    "\n",
    "print(f\"total mem: {t}\\nreserved: {r}\\nallocated: {a}\\nfree in reserve: {f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(\"./results/checkpoint-1500\")\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
    "sentiment_classifier = pipeline('sentiment-analysis', model=model, tokenizer=tokenizer)\n",
    "testcase = \"This is not working. I'm waiting on it for days now\"\n",
    "sentiment_classifier(testcase)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
